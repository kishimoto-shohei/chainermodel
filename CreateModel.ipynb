{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/chainer_p36/lib/python3.6/site-packages (19.0.1)\n",
      "Collecting opencv-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/49/874d119948a5a084a7ebe98308214098ef3471d76ab74200f9800efeef15/opencv_python-4.0.0.21-cp36-cp36m-manylinux1_x86_64.whl (25.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 25.4MB 2.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/chainer_p36/lib/python3.6/site-packages (from opencv-python) (1.14.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.0.0.21\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import chainer\n",
    "from chainer.datasets import ConcatenatedDataset\n",
    "from chainer.datasets import TransformDataset\n",
    "from chainer.optimizer import WeightDecay\n",
    "from chainer import serializers\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "from chainer.training import triggers\n",
    "\n",
    "from chainercv.datasets import voc_bbox_label_names\n",
    "from chainercv.links.model.ssd import GradientScaling\n",
    "from chainercv.links.model.ssd import multibox_loss\n",
    "from chainercv.links import SSD300\n",
    "from chainercv.links import SSD512\n",
    "from chainercv import transforms\n",
    "\n",
    "from chainercv.links.model.ssd import random_crop_with_bbox_constraints\n",
    "from chainercv.links.model.ssd import random_distort\n",
    "from chainercv.links.model.ssd import resize_with_random_interpolation\n",
    "\n",
    "from datasetfromdat import DatasetFromDat\n",
    "from via_utils import via_bbox_label_names\n",
    "from via_detection_evaluator import DetectionEvaluator\n",
    "\n",
    "class MultiboxTrainChain(chainer.Chain):\n",
    "\n",
    "    def __init__(self, model, alpha=1, k=3):\n",
    "        super(MultiboxTrainChain, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.model = model\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "\n",
    "    def __call__(self, imgs, gt_mb_locs, gt_mb_labels):\n",
    "        mb_locs, mb_confs = self.model(imgs)\n",
    "        loc_loss, conf_loss = multibox_loss(\n",
    "            mb_locs, mb_confs, gt_mb_locs, gt_mb_labels, self.k)\n",
    "        loss = loc_loss * self.alpha + conf_loss\n",
    "\n",
    "        chainer.reporter.report(\n",
    "            {'loss': loss, 'loss/loc': loc_loss, 'loss/conf': conf_loss},\n",
    "            self)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "\n",
    "class Transform(object):\n",
    "\n",
    "    def __init__(self, coder, size, mean):\n",
    "        # to send cpu, make a copy\n",
    "        self.coder = copy.copy(coder)\n",
    "        self.coder.to_cpu()\n",
    "\n",
    "        self.size = size\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, in_data):\n",
    "        # There are five data augmentation steps\n",
    "        # 1. Color augmentation\n",
    "        # 2. Random expansion\n",
    "        # 3. Random cropping\n",
    "        # 4. Resizing with random interpolation\n",
    "        # 5. Random horizontal flipping\n",
    "\n",
    "        img, bbox, label = in_data\n",
    "\n",
    "        # 1. Color augmentation\n",
    "        img = random_distort(img)\n",
    "\n",
    "        # 2. Random expansion\n",
    "        if np.random.randint(2):\n",
    "            img, param = transforms.random_expand(\n",
    "                img, fill=self.mean, return_param=True)\n",
    "            bbox = transforms.translate_bbox(\n",
    "                bbox, y_offset=param['y_offset'], x_offset=param['x_offset'])\n",
    "\n",
    "        # 3. Random cropping\n",
    "        img, param = random_crop_with_bbox_constraints(\n",
    "            img, bbox, return_param=True)\n",
    "        bbox, param = transforms.crop_bbox(\n",
    "            bbox, y_slice=param['y_slice'], x_slice=param['x_slice'],\n",
    "            allow_outside_center=False, return_param=True)\n",
    "        label = label[param['index']]\n",
    "\n",
    "        # 4. Resizing with random interpolatation\n",
    "        _, H, W = img.shape\n",
    "        img = resize_with_random_interpolation(img, (self.size, self.size))\n",
    "        bbox = transforms.resize_bbox(bbox, (H, W), (self.size, self.size))\n",
    "\n",
    "        # 5. Random horizontal flipping\n",
    "        img, params = transforms.random_flip(\n",
    "            img, x_random=True, return_param=True)\n",
    "        bbox = transforms.flip_bbox(\n",
    "            bbox, (self.size, self.size), x_flip=params['x_flip'])\n",
    "\n",
    "        # Preparation for SSD network\n",
    "        img -= self.mean\n",
    "        mb_loc, mb_label = self.coder.encode(bbox, label)\n",
    "\n",
    "        return img, mb_loc, mb_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSD300(\n",
    "    n_fg_class=len(voc_bbox_label_names),\n",
    "    pretrained_model='voc0712')\n",
    "\n",
    "model.use_preset('evaluate')\n",
    "train_chain = MultiboxTrainChain(model)\n",
    "\n",
    "#chainer.cuda.get_device_from_id(0).use()\n",
    "#model.to_gpu()\n",
    "\n",
    "train = TransformDataset(\n",
    "    DatasetFromDat(file_path = 'Rack.dat'),\n",
    "    Transform(model.coder, model.insize, model.mean))\n",
    "train_iter = chainer.iterators.MultiprocessIterator(train, 6)\n",
    "\n",
    "test = DatasetFromDat('Rack_val.dat')\n",
    "test_iter = chainer.iterators.SerialIterator(\n",
    "    test, 6, repeat=False, shuffle=False)\n",
    "\n",
    "# initial lr is set to 1e-3 by ExponentialShift\n",
    "optimizer = chainer.optimizers.MomentumSGD()\n",
    "optimizer.setup(train_chain)\n",
    "for param in train_chain.params():\n",
    "    if param.name == 'b':\n",
    "        param.update_rule.add_hook(GradientScaling(2))\n",
    "    else:\n",
    "        param.update_rule.add_hook(WeightDecay(0.0005))\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=-1)\n",
    "# 120000->8000\n",
    "trainer = training.Trainer(updater, (500, 'iteration'), 'result')\n",
    "# 80000->5000,100000->7000\n",
    "trainer.extend(\n",
    "    extensions.ExponentialShift('lr', 0.1, init=1e-3),\n",
    "    trigger=triggers.ManualScheduleTrigger([300, 400], 'iteration'))\n",
    "# 10000->700\n",
    "trainer.extend(\n",
    "    DetectionEvaluator(\n",
    "        test_iter, model, use_07_metric=True,\n",
    "        label_names=via_bbox_label_names),\n",
    "    trigger=(7, 'iteration'))\n",
    "log_interval = 10, 'iteration'\n",
    "trainer.extend(extensions.LogReport(trigger=log_interval))\n",
    "trainer.extend(extensions.observe_lr(), trigger=log_interval)\n",
    "trainer.extend(extensions.PrintReport(\n",
    "    ['epoch', 'iteration', 'lr',\n",
    "     'main/loss', 'main/loss/loc', 'main/loss/conf',\n",
    "     'validation/main/map']),\n",
    "    trigger=log_interval)\n",
    "trainer.extend(extensions.ProgressBar(update_interval=10))\n",
    "# 10000->700\n",
    "trainer.extend(extensions.snapshot(), trigger=(50, 'iteration'))\n",
    "# 120000->8000\n",
    "trainer.extend(\n",
    "    extensions.snapshot_object(model, 'model_iter_{.updater.iteration}'),\n",
    "    trigger=(500, 'iteration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/chainer_p36/lib/python3.6/site-packages/chainercv/transforms/image/resize.py:33: RuntimeWarning: cv2 is not installed on your environment. ChainerCV will fall back on Pillow. Installation of cv2 is recommended for faster computation. \n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       iteration   lr          main/loss   main/loss/loc  main/loss/conf  validation/main/map\n",
      "\u001b[J0           10          0.001       7.47845     2.28332        5.19514         0.0132312            \n",
      "\u001b[J     total [#.................................................]  2.00%\n",
      "this epoch [##########........................................] 20.00%\n",
      "        10 iter, 0 epoch / 500 iterations\n",
      "       inf iters/sec. Estimated time to finish: 0:00:00.\n",
      "\u001b[4A\u001b[J0           20          0.001       7.2191      2.4708         4.7483          0.0999519            \n",
      "\u001b[J     total [##................................................]  4.00%\n",
      "this epoch [####################..............................] 40.00%\n",
      "        20 iter, 0 epoch / 500 iterations\n",
      "   0.12944 iters/sec. Estimated time to finish: 1:01:48.273239.\n",
      "\u001b[4A\u001b[J0           30          0.001       7.20564     2.64248        4.56316         0.0321403            \n",
      "\u001b[J     total [###...............................................]  6.00%\n",
      "this epoch [##############################....................] 60.00%\n",
      "        30 iter, 0 epoch / 500 iterations\n",
      "  0.079964 iters/sec. Estimated time to finish: 1:37:57.675097.\n",
      "\u001b[4A\u001b[J0           40          0.001       7.41984     2.56441        4.85543         0.00471766           \n",
      "\u001b[J     total [####..............................................]  8.00%\n",
      "this epoch [########################################..........] 80.00%\n",
      "        40 iter, 0 epoch / 500 iterations\n",
      "  0.088067 iters/sec. Estimated time to finish: 1:27:03.283770.\n",
      "\u001b[4A\u001b[J1           50          0.001       7.02805     2.61537        4.41269         0.0449732            \n",
      "\u001b[J     total [#####.............................................] 10.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "        50 iter, 1 epoch / 500 iterations\n",
      "  0.091508 iters/sec. Estimated time to finish: 1:21:57.626593.\n",
      "\u001b[4A\u001b[J1           60          0.001       6.66049     2.85783        3.80266         0.0127523            \n",
      "\u001b[J     total [######............................................] 12.00%\n",
      "this epoch [#########.........................................] 20.00%\n",
      "        60 iter, 1 epoch / 500 iterations\n",
      "   0.09526 iters/sec. Estimated time to finish: 1:16:58.949802.\n",
      "\u001b[4A\u001b[J1           70          0.001       6.87865     2.98616        3.89248         0.012573             \n",
      "\u001b[J     total [#######...........................................] 14.00%\n",
      "this epoch [###################...............................] 40.00%\n",
      "        70 iter, 1 epoch / 500 iterations\n",
      "  0.065084 iters/sec. Estimated time to finish: 1:50:06.859916.\n",
      "\u001b[4A\u001b[J1           80          0.001       6.72253     2.67919        4.04334         0.156971             \n",
      "\u001b[J     total [########..........................................] 16.00%\n",
      "this epoch [##############################....................] 60.00%\n",
      "        80 iter, 1 epoch / 500 iterations\n",
      "  0.057628 iters/sec. Estimated time to finish: 2:01:28.154509.\n",
      "\u001b[4A\u001b[J1           90          0.001       5.59683     2.45048        3.14636         0.104996             \n",
      "\u001b[J     total [#########.........................................] 18.00%\n",
      "this epoch [########################################..........] 80.00%\n",
      "        90 iter, 1 epoch / 500 iterations\n",
      "  0.052664 iters/sec. Estimated time to finish: 2:09:45.174329.\n",
      "\u001b[4A\u001b[J2           100         0.001       5.2612      2.30945        2.95175         0.0650514            \n",
      "\u001b[J     total [##########........................................] 20.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "       100 iter, 2 epoch / 500 iterations\n",
      "  0.045394 iters/sec. Estimated time to finish: 2:26:51.703056.\n",
      "\u001b[4A"
     ]
    }
   ],
   "source": [
    "trainer.run()\n",
    "serializers.save_npz('via_model.npz', model)\n",
    "serializers.save_npz('via_state.npz', optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14:33 1:01:48.273239.\n",
    "# 14:37 1:21:57.626593.\n",
    "# 14:41 1:16:58.949802.\n",
    "# 14:46 1:50:06.859916.\n",
    "# 14:51 2:01:28.154509.\n",
    "# 14:57 2:09:45.174329.\n",
    "# 15:04 2:26:51.703056."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_chainer_p36",
   "language": "python",
   "name": "conda_chainer_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
